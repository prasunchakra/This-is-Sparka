{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.appName(\"BroadcastAccumulators\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Covered\n",
    "\n",
    "* **pyspark.sql.functions**\n",
    "    * udf\n",
    "    * broadcast\n",
    "    \n",
    "* **DataFrames**\n",
    "    * join\n",
    "    * sort\n",
    "    * foreach\n",
    "    * coalesce\n",
    "    * write <option /csv|json>\n",
    "* **sc: Spark Context**\n",
    "    * accumulator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = spark.read\\\n",
    "               .format(\"csv\")\\\n",
    "               .option(\"header\", \"true\")\\\n",
    "               .load(\"./datasets/player.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_attributes = spark.read\\\n",
    "                         .format(\"csv\")\\\n",
    "                         .option(\"header\", \"true\")\\\n",
    "                         .load(\"./datasets/player_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = players.drop('id', 'player_fifa_api_id')\n",
    "player_attributes = player_attributes.drop('id', 'player_fifa_api_id', 'preferred_foot','attacking_work_rate',\n",
    "                                           'defensive_work_rate','crossing','jumping','sprint_speed','balance',\n",
    "                                           'aggression','short_passing','potential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf #user defined function\n",
    "year_extract_udf = udf(lambda date: date.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[player_api_id: string, date: string, overall_rating: string, finishing: string, heading_accuracy: string, volleys: string, dribbling: string, curve: string, free_kick_accuracy: string, long_passing: string, ball_control: string, acceleration: string, agility: string, reactions: string, shot_power: string, stamina: string, strength: string, long_shots: string, interceptions: string, positioning: string, vision: string, penalties: string, marking: string, standing_tackle: string, sliding_tackle: string, gk_diving: string, gk_handling: string, gk_kicking: string, gk_positioning: string, gk_reflexes: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_attributes = player_attributes.withColumn(\n",
    "    \"year\",\n",
    "    year_extract_udf(player_attributes.date)\n",
    ")\n",
    "player_attributes.drop(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_2016 = player_attributes.filter(player_attributes.year == 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-----------------+----------+\n",
      "|player_api_id|        finishing|     acceleration|shot_power|\n",
      "+-------------+-----------------+-----------------+----------+\n",
      "|       309726|75.44444444444444|74.11111111111111|      76.0|\n",
      "|        26112|             53.0|             51.0|      76.0|\n",
      "|        38433|            68.25|             74.0|      74.0|\n",
      "|       295060|             25.0|             62.0|      40.0|\n",
      "|       161396|             29.0|             72.0|      69.0|\n",
      "+-------------+-----------------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pa_striker_2016 = pa_2016.groupBy('player_api_id')\\\n",
    "                       .agg({\n",
    "                           'finishing':\"avg\",\n",
    "                           \"shot_power\":\"avg\",\n",
    "                           \"acceleration\":\"avg\"})\\\n",
    "                        .withColumnRenamed(\"avg(finishing)\",\"finishing\")\\\n",
    "                        .withColumnRenamed(\"avg(shot_power)\",\"shot_power\")\\\n",
    "                        .withColumnRenamed(\"avg(acceleration)\",\"acceleration\")\n",
    "pa_striker_2016.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_finishing = 1\n",
    "weight_shot_power = 2\n",
    "weight_acceleration = 1\n",
    "\n",
    "total_weight = weight_finishing + weight_shot_power + weight_acceleration\n",
    "strikers = pa_striker_2016.withColumn(\"striker_grade\",\n",
    "                                      (pa_striker_2016.finishing * weight_finishing + \\\n",
    "                                       pa_striker_2016.shot_power * weight_shot_power+ \\\n",
    "                                       pa_striker_2016.acceleration * weight_acceleration) / total_weight)\n",
    "strikers = strikers.drop('finishing',\n",
    "                         'acceleration',\n",
    "                         'shot_power'\n",
    ")\n",
    "strikers = strikers.filter(strikers.striker_grade > 70)\\\n",
    "                   .sort(strikers.striker_grade.desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-------------------+------+------+\n",
      "|player_api_id|       player_name|           birthday|height|weight|\n",
      "+-------------+------------------+-------------------+------+------+\n",
      "|       505942|Aaron Appindangoye|1992-02-29 00:00:00|182.88|   187|\n",
      "|       155782|   Aaron Cresswell|1989-12-15 00:00:00|170.18|   146|\n",
      "|       162549|       Aaron Doran|1991-05-13 00:00:00|170.18|   163|\n",
      "|        30572|     Aaron Galindo|1982-05-08 00:00:00|182.88|   198|\n",
      "|        23780|      Aaron Hughes|1979-11-08 00:00:00|182.88|   154|\n",
      "+-------------+------------------+-------------------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|player_api_id|striker_grade|\n",
      "+-------------+-------------+\n",
      "|        20276|        89.25|\n",
      "|        37412|         89.0|\n",
      "|        38817|        88.75|\n",
      "|        32118|        88.25|\n",
      "|        31921|         87.0|\n",
      "+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strikers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------------------+------+------+-------------+-------------+\n",
      "|player_api_id|   player_name|           birthday|height|weight|player_api_id|striker_grade|\n",
      "+-------------+--------------+-------------------+------+------+-------------+-------------+\n",
      "|        20276|          Hulk|1986-07-25 00:00:00|180.34|   187|        20276|        89.25|\n",
      "|        37412| Sergio Aguero|1988-06-02 00:00:00|172.72|   163|        37412|         89.0|\n",
      "|        38817|  Carlos Tevez|1984-02-05 00:00:00|172.72|   157|        38817|        88.75|\n",
      "|        32118|Lukas Podolski|1985-06-04 00:00:00|182.88|   183|        32118|        88.25|\n",
      "|        31921|   Gareth Bale|1989-07-16 00:00:00|182.88|   163|        31921|         87.0|\n",
      "+-------------+--------------+-------------------+------+------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "striker_details = players.join(strikers, players.player_api_id == strikers.player_api_id)\n",
    "striker_details.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------------------+------+------+-------------+\n",
      "|player_api_id|   player_name|           birthday|height|weight|striker_grade|\n",
      "+-------------+--------------+-------------------+------+------+-------------+\n",
      "|        20276|          Hulk|1986-07-25 00:00:00|180.34|   187|        89.25|\n",
      "|        37412| Sergio Aguero|1988-06-02 00:00:00|172.72|   163|         89.0|\n",
      "|        38817|  Carlos Tevez|1984-02-05 00:00:00|172.72|   157|        88.75|\n",
      "|        32118|Lukas Podolski|1985-06-04 00:00:00|182.88|   183|        88.25|\n",
      "|        31921|   Gareth Bale|1989-07-16 00:00:00|182.88|   163|         87.0|\n",
      "+-------------+--------------+-------------------+------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "striker_details = players.join(strikers, ['player_api_id'])\n",
    "striker_details.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It might not be obvious when we are writing the code but in order to perform join operations behind the scenes on a spark cluster we have to transmit the content of one dataframe to where the the content of the other data frame are located. We ensure that there is only one copy per node by using the broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadcast the smaller dataframe so it is available on all cluster machines\n",
    "striker_details = players.select(\n",
    "                                \"player_api_id\",\n",
    "                                \"player_name\"\n",
    "                                 )\\\n",
    "                  .join(\n",
    "                        broadcast(strikers), \n",
    "                        ['player_api_id'],   \n",
    "                        'inner'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------------+\n",
      "|player_api_id|   player_name|striker_grade|\n",
      "+-------------+--------------+-------------+\n",
      "|        20276|          Hulk|        89.25|\n",
      "|        37412| Sergio Aguero|         89.0|\n",
      "|        38817|  Carlos Tevez|        88.75|\n",
      "|        32118|Lukas Podolski|        88.25|\n",
      "|        31921|   Gareth Bale|         87.0|\n",
      "+-------------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "striker_details = striker_details.sort(striker_details.striker_grade.desc())\n",
    "striker_details.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_heading_acc = player_attributes.select('player_api_id',\n",
    "                                               'heading_accuracy')\\\n",
    "                                       .join(broadcast(players),\n",
    "                                             player_attributes.player_api_id == players.player_api_id)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Counting the number of players that falls in each of these buckets because is not as straightforward as it shounds because spark is a distributed processing system. The count variable that will hold the totals needs to be shared accross all compute nodes and this is where accumulators comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_count = spark.sparkContext.accumulator(0)\n",
    "medium_low_count = spark.sparkContext.accumulator(0)\n",
    "medium_high_count = spark.sparkContext.accumulator(0)\n",
    "tall_count = spark.sparkContext.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_players_by_height(row):\n",
    "    height = float(row.height)\n",
    "    \n",
    "    if (height <= 175 ):\n",
    "        short_count.add(1)\n",
    "    elif (height <= 183 and height > 175 ):\n",
    "        medium_low_count.add(1)\n",
    "    elif (height <= 195 and height > 183 ):\n",
    "        medium_high_count.add(1)\n",
    "    elif (height > 195) :\n",
    "        tall_count.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19204, 98958, 62411, 3405]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_heading_acc.foreach(lambda x: count_players_by_height(x))\n",
    "all_players = [short_count.value,\n",
    "               medium_low_count.value,\n",
    "               medium_high_count.value,\n",
    "               tall_count.value]\n",
    "\n",
    "all_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_2016.select(\"player_api_id\", \"overall_rating\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"players_overall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_2016.select(\"player_api_id\", \"overall_rating\")\\\n",
    "    .write\\\n",
    "    .json(\"players_overall.json\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Individual records in a dataframes will be split accross multiple nodes in a spark clusters. The coalesce function is used with an input argument to repartition the dataframe into a single partition here to write out a single file. On removal of coalesce the number of files written out will be equal to the number of partitions of that dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
