{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.42.118:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics Covered\n",
    "\n",
    "* **sc: Spark Context**\n",
    "    * parallelize\n",
    "    * sqlContext=SQLContext(sc)\n",
    "* **rdd: resilient distributed datasets**\n",
    "    * count\n",
    "    * first\n",
    "    * take\n",
    "    * collect\n",
    "    * toDF\n",
    "    * map\n",
    "* **df: DataFrames**\n",
    "    * show\n",
    "    * collect\n",
    "    * rdd\n",
    "    * select\n",
    "    * withColumn\n",
    "    * withColumnRenamed\n",
    "    * toPandas\n",
    "* **sqlContext**\n",
    "    * range\n",
    "    * createDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Python List to RDD\n",
    "pyRDD = sc.parallelize([1,'One',True])\n",
    "pyRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 [1, 'One'] [1, 'One', True]\n"
     ]
    }
   ],
   "source": [
    "#Actions on RDD\n",
    "print(pyRDD.count(),pyRDD.first(),pyRDD.take(2),pyRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyDF=pyRDD.toDF() #TypeError: Can not infer schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: bigint, _2: string, _3: boolean]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD made up of structured data can be converted to Data Frames\n",
    "df = sc.parallelize([[0,'Zero',False],[1,'One',True]]).toDF()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "| _1|  _2|   _3|\n",
      "+---+----+-----+\n",
      "|  0|Zero|false|\n",
      "|  1| One| true|\n",
      "+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "|  i|   j|    k|\n",
      "+---+----+-----+\n",
      "|  0|Zero|false|\n",
      "|  1| One| true|\n",
      "+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "df = sc.parallelize([Row(i=0,j='Zero',k=False),Row(i=1,j='One',k=True)]).toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f5b87f9eef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext=SQLContext(sc)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=sqlContext.range(5)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Score|\n",
      "+-------+-----+\n",
      "| Sachin|   90|\n",
      "|Ganguly|  100|\n",
      "| Dravid|   80|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SqlContext to create data from array\n",
    "data=[('Sachin',90),('Ganguly',100),('Dravid',80)]\n",
    "df=sqlContext.createDataFrame(data,['Name','Score'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---------------+\n",
      "|  i|   j|    k|              l|\n",
      "+---+----+-----+---------------+\n",
      "|  0|Zero|false|[1, 3, 5, 7, 9]|\n",
      "|  1| One| true|   [2, 4, 6, 8]|\n",
      "+---+----+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SqlContext to create data from RDD\n",
    "rdd= sc.parallelize([Row(i=0,j='Zero',k=False,l=[1,3,5,7,9]),Row(i=1,j='One',k=True,l=[2,4,6,8])])\n",
    "df=sqlContext.createDataFrame(rdd)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cell=df.collect()[0][3]\n",
    "list_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cell.append(11)\n",
    "list_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---------------+\n",
      "|  i|   j|    k|              l|\n",
      "+---+----+-----+---------------+\n",
      "|  0|Zero|false|[1, 3, 5, 7, 9]|\n",
      "|  1| One| true|   [2, 4, 6, 8]|\n",
      "+---+----+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show() # The original cell in the data frame remains unchanged, a copy is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(i=0, j='Zero', k=False, l=[1, 3, 5, 7, 9]),\n",
       " Row(i=1, j='One', k=True, l=[2, 4, 6, 8])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD equivalent of the dataframe\n",
    "df.rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zero', False), ('One', True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select Specific columns from the RDD\n",
    "df.rdd.map(lambda x:(x.j,x.k)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "|  i|              l|\n",
      "+---+---------------+\n",
      "|  0|[1, 3, 5, 7, 9]|\n",
      "|  1|   [2, 4, 6, 8]|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select Specific columns from the DataFrame\n",
    "df.select('i','l').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9],\n",
       " [2, 4, 6, 8, 2, 4, 6, 8, 2, 4, 6, 8]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Operate on specific column RDD\n",
    "df.rdd.map(lambda x:(x.l*3)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|    k|toggle|\n",
      "+-----+------+\n",
      "|false|  true|\n",
      "| true| false|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Operate on specific column DataFrame & renaming DataFrame column\n",
    "df.select('k').withColumn(\"l\",df.k==False).withColumnRenamed(\"l\",\"toggle\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Booleam|\n",
      "+-------+\n",
      "|  false|\n",
      "|   true|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Column Rename\n",
    "df.select(df.k.alias(\"Booleam\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "#Spark DataFrames are built on top of RDDs and distributed accross multiple nodes in a spark cluster,\n",
    "#Pandas dataframe will be in memory on a single machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Zero</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 3, 5, 7, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>One</td>\n",
       "      <td>True</td>\n",
       "      <td>[2, 4, 6, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i     j      k                l\n",
       "0  0  Zero  False  [1, 3, 5, 7, 9]\n",
       "1  1   One   True     [2, 4, 6, 8]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df=df.toPandas()\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---------------+\n",
      "|  i|   j|    k|              l|\n",
      "+---+----+-----+---------------+\n",
      "|  0|Zero|false|[1, 3, 5, 7, 9]|\n",
      "|  1| One| true|   [2, 4, 6, 8]|\n",
      "+---+----+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df=sqlContext.createDataFrame(pandas_df)\n",
    "spark_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
